<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: models.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: models.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>import * as cocoSsd from "@tensorflow-models/coco-ssd";

export class Library {
  /**
   * Static metadata registry for available projects/models.
   * Can be extended or replaced by external JSON config.
   */
  static data = {
    projects: {
      tf: {
        list: false,
        title: "Pre-trained models available in TensorFlow.js",
        website: "https://github.com/tensorflow/tfjs-models",
        about: {
          en: "A collection of ready-to-use machine learning models, optimized for TensorFlow.js and the browser. These models cover tasks such as object detection, image classification, and more.",
          de: "Eine Sammlung gebrauchsfertiger Machine-Learning-Modelle, optimiert für TensorFlow.js und die Ausführung im Browser. Die Modelle decken Aufgaben wie Objekterkennung, Bildklassifikation und weitere Anwendungsfälle ab.",
        },
        models: {
          "coco-ssd": {
            active: true,
            type: "object_detection",
            model_input: ["image"],
            model_input_options: {
              normalize: false,
              addBatchDim: false,
            },
            model_output: "bounding_boxes",
            title: {
              en: "Detect Objects in Images",
              de: "Objekte in Bildern erkennen",
            },
            description: {
              en: "This pre-trained object detection model can identify and localize multiple objects within a single image. By uploading an image, the model will detect common objects such as people, cars, or animals and mark them with bounding boxes.",
              de: "Dieses vortrainierte Objekterkennungsmodell kann mehrere Objekte in einem einzelnen Bild identifizieren und lokalisieren. Nach dem Hochladen eines Bildes erkennt das Modell gängige Objekte wie Personen, Autos oder Tiere und markiert sie mit Begrenzungsrahmen.",
            },
            images: {
              input: "library/assets/object_input.png",
              output: "library/assets/object_output.png",
              icon: "library/assets/object_icon.png",
            },
            path: "",
          },
        },
      },

      bagls: {
        list: true,
        title: "The BAGLS project: Benchmark for Automatic Glottis Segmentation",
        website: "https://www.bagls.org/",
        about: {
          en: "BAGLS is the first large-scale, publicly available dataset of endoscopic high-speed video with frame-wise segmentation annotations. Collected in collaboration with seven institutions, it comprises 59,250 annotated frames.",
          de: "BAGLS ist der erste groß angelegte, frei verfügbare Datensatz aus endoskopischen Hochgeschwindigkeitsvideos mit bildweisen Segmentierungsannotationen. Er wurde in Zusammenarbeit mit sieben Einrichtungen erstellt und umfasst 59.250 annotierte Frames.",
        },

        models: {
          segment: {
            active: true,
            type: "segment_image",
            model_input: ["image", "video"],
            model_input_options: {
              inputShape: [1, 256, 256, 3],
              dtype: "float32",
              normalize: true,
              addBatchDim: true,
              targetHeight: 256,
              targetWidth: 256,
            },
            model_output: "image_segmentation",
            title: {
              en: "Segment the glottis in endoscopy data",
              de: "Glottis in Endoskopie-Daten segmentieren",
            },
            description: {
              en: "Upload endoscopy images or videos and the model will automatically outline the glottis (the opening between the vocal cords).",
              de: "Laden Sie Endoskopie-Bilder oder -Videos hoch; das Modell markiert automatisch die Glottis (die Öffnung zwischen den Stimmbändern).",
            },
            path: "library/bagls_rgb",
            images: {
              input: "library/assets/bagls_input.png",
              output: "library/assets/bagls_output.png",
              icon: "library/assets/bagls_icon.png",
            },
          },
        },
      },
    },
  };

  /**
   * Load static or remote model registry.
   */
  static load_data() {
    // Future: replace with fetch if external registry is needed
    return this.data;
  }

  /**
   * Return a flattened list of all models across projects.
   * Useful for building dropdowns or UIs.
   */
  static async get_model_list() {
    const data = this.load_data();
    const result = [];

    for (const [projectKey, project] of Object.entries(data.projects)) {
      if (!project.models) continue;
      for (const [modelKey, model] of Object.entries(project.models)) {
        result.push({
          label: model.title,
          value: `${projectKey}.${modelKey}`,
          type: model.type,
          description: model.description,
        });
      }
    }
    return result;
  }

  /**
   * Get a model definition object by project/model key.
   * @param {string|array} args - "project.model" or [project, model]
   */
  static async get_model(...args) {
    const data = this.load_data();
    let projectKey, modelKey;
    console.log(args);
    if (args.length === 1) {
      [projectKey, modelKey] = args[0].split(".");
    } else if (args.length === 2) {
      [projectKey, modelKey] = args;
    } else {
      throw new Error(
        "Invalid arguments: must be 'project.model' or [project, model]"
      );
    }

    const project = data.projects[projectKey];
    if (!project || !project.models || !project.models[modelKey]) return null;

    return project.models[modelKey] || null;
  }

  /**
   * Load a TensorFlow.js model.
   * Supports both prepackaged models (like coco-ssd) and custom paths.
   * @param {object} env - injected environment with tf + path resolver
   * @param {string} modelKey - full key like "tf.coco-ssd"
   */
  static async load_model(env, basePath, modelKey) {
    if (!env || !env.tf) throw new Error("env with tf required");

    const modelInfo = await this.get_model(modelKey);
    if (!modelInfo) throw new Error(`Model not found: ${modelKey}`);

    // Special case for prebuilt models
    if (modelKey === "tf.coco-ssd") {
      return await cocoSsd.load();
    }

    // Otherwise use standard tf.loadLayersModel
    if (modelInfo.path) {
      // const basePath = env.resolveModelLibraryPath();
      const modelUrl = `${basePath}${modelInfo.path}/model.json`;
      return await env.tf.loadLayersModel(modelUrl);
    }

    throw new Error(`No valid loader for model: ${modelKey}`);
  }

  /**
   * Get canonical input options for a model.
   * Used to normalize data preparation across different models.
   * Returns only standard fields: { inputShape, dtype, normalize, addBatchDim }
   */
  static get_model_options(modelName, model = null) {
    // Special-case: coco-ssd (dynamic H/W, no batch, no normalize, int32)
    if (modelName === "tf.coco-ssd") {
      return {
        inputShape: [1, -1, -1, 3],
        dtype: "int32",
        normalize: false,
        addBatchDim: false,
      };
    }

    const defaults = {
      inputShape: [1, 224, 224, 3],
      dtype: "float32",
      normalize: true,
      addBatchDim: true,
    };

    // 1) Registry (if available)
    const data = this.load_data();
    const [projectKey, modelKey] = (modelName || "").split(".");
    if (!projectKey || !modelKey)
      throw new Error("invalid model name (expected 'project.model')");
    const reg = data?.projects?.[projectKey]?.models?.[modelKey];

    const fromRegistry = {};
    if (reg?.model_input_options) {
      const mio = reg.model_input_options;
      if (mio.inputShape) fromRegistry.inputShape = mio.inputShape;
      if (mio.dtype) fromRegistry.dtype = mio.dtype;
      if (typeof mio.normalize !== "undefined")
        fromRegistry.normalize = mio.normalize;
      if (typeof mio.addBatchDim !== "undefined")
        fromRegistry.addBatchDim = mio.addBatchDim;
    }

    // 2) Inference from loaded model (optional)
    const fromModel = {};
    if (model &amp;&amp; Array.isArray(model.inputs) &amp;&amp; model.inputs.length) {
      const t = model.inputs[0];
      const shape = (t.shape || []).map((d, i) =>
        d == null || d &lt; 0 ? (i === 0 ? 1 : -1) : d
      );
      if (shape.length) fromModel.inputShape = shape;
      if (t.dtype) fromModel.dtype = t.dtype;
      // Heuristic: 4D input -> batch dim likely present
      if (shape.length) fromModel.addBatchDim = shape.length > 3;
      // Keep normalize default unless registry overrides it
    }

    // 3) Merge: defaults &lt; fromModel &lt; fromRegistry
    const merged = { ...defaults, ...fromModel, ...fromRegistry };

    // 4) Sanitize shape to 4D and batch dim if requested
    let s = merged.inputShape;
    if (Array.isArray(s)) {
      if (s.length === 3 &amp;&amp; merged.addBatchDim) s = [1, ...s];
      if (s.length === 4) {
        // Ensure batch is concrete (1), keep H/W dynamic if unknown
        s = s.map((d, i) => (d == null || d &lt; 0 ? (i === 0 ? 1 : -1) : d));
      }
      merged.inputShape = s;
    } else {
      merged.inputShape = defaults.inputShape;
    }

    // 5) Return only standard keys
    const { inputShape, dtype, normalize, addBatchDim } = merged;
    return { inputShape, dtype, normalize, addBatchDim };
  }
}
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Data.html">Data</a></li><li><a href="InferenceTask.html">InferenceTask</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 4.0.4</a> on Wed Sep 10 2025 14:35:26 GMT+0200 (Central European Summer Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
